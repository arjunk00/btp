{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2087839d-5d9c-411f-89db-220bfb78de3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 21:51:04.503253: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-23 21:51:04.537854: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-23 21:51:04.537880: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-23 21:51:04.538692: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-23 21:51:04.543758: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-23 21:51:04.544312: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-23 21:51:05.361214: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AlbertTokenizer, TFAlbertForSequenceClassification\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5df027a-a521-49d7-9400-2494074b45e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From the moment that the French defenses at Se...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We observe today not a victory of party but a ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Your Majesties, Your Highnesses, Distinguished...</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am honored to be with you today at your comm...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Honorable UN Secretary General Mr Ban Ki-moon,...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>It is with a profound sense of humility that I...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>My message is that we'll be watching you.\\r\\n\\...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hello everybody. You know, Michelle and I have...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Your Majesties, Your Royal Highness, Excellenc...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Five score years ago, a great American, in who...</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              speech       emotion\n",
       "0  From the moment that the French defenses at Se...         anger\n",
       "1  We observe today not a victory of party but a ...           joy\n",
       "2  Your Majesties, Your Highnesses, Distinguished...         trust\n",
       "3  I am honored to be with you today at your comm...  anticipation\n",
       "4  Honorable UN Secretary General Mr Ban Ki-moon,...       sadness\n",
       "5  It is with a profound sense of humility that I...       sadness\n",
       "6  My message is that we'll be watching you.\\r\\n\\...          fear\n",
       "7  Hello everybody. You know, Michelle and I have...           joy\n",
       "8  Your Majesties, Your Royal Highness, Excellenc...  anticipation\n",
       "9  Five score years ago, a great American, in who...         trust"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('one_output_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb4bcaf4-b4d1-4974-8b2f-0c712520c3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/arjun/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/arjun/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#preprocess transcript\n",
    "\n",
    "# download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# initialize a PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # lowercase the text\n",
    "    text = text.lower()\n",
    "    # remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    # remove stopwords and stem the words\n",
    "    words = [stemmer.stem(word) for word in words if word not in stopwords.words('english')]\n",
    "    # join the words back into a string\n",
    "    text = ' '.join(words)\n",
    "\n",
    "    return text\n",
    "\n",
    "df['speech'] = df['speech'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c15a2034-bacc-4684-88e7-1e387b3263f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading spiece.model: 100%|███████████████| 760k/760k [00:01<00:00, 741kB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 1.31M/1.31M [00:00<00:00, 1.39MB/s]\n",
      "2023-11-23 21:51:21.701741: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-11-23 21:51:21.701775: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: fernblade\n",
      "2023-11-23 21:51:21.701783: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: fernblade\n",
      "2023-11-23 21:51:21.701903: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 545.29.2\n",
      "2023-11-23 21:51:21.701927: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 545.29.2\n",
      "2023-11-23 21:51:21.701934: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 545.29.2\n",
      "All PyTorch model weights were used when initializing TFAlbertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFAlbertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer=AlbertTokenizer.from_pretrained('albert-large-v2')\n",
    "\n",
    "model=TFAlbertForSequenceClassification.from_pretrained('albert-large-v2',num_labels=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee54acf8-ecf1-492c-8ad7-763b0c5e1d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d2f45b0-152d-434a-88e9-6e9dc3b414d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split in train and test in text and labels\n",
    "train_texts = train['speech'].tolist()\n",
    "train_labels = train['emotion'].tolist()\n",
    "\n",
    "test_texts = test['speech'].tolist()\n",
    "test_labels = test['emotion'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57e46441-fe6d-4948-b13c-c0d2dba19664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the texts\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a560740-c3b5-4781-9c07-b27264980eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert features and labels to tensors for both train and test\n",
    "train_features = {key: tf.convert_to_tensor(val) for key, val in train_encodings.items()}\n",
    "train_labels = tf.convert_to_tensor(train_labels)\n",
    "\n",
    "test_features = {key: tf.convert_to_tensor(val) for key, val in test_encodings.items()}\n",
    "test_labels = tf.convert_to_tensor(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "028556e4-ebb3-4155-978b-6e41862c0748",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the training and testing dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_features, train_labels))\n",
    "train_dataset = train_dataset.shuffle(10000).batch(2)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_features, test_labels))\n",
    "test_dataset = test_dataset.batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "978195e4-9ece-4bb5-b0de-ab44b9c77c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model metrics\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdbe304f-aaef-43ea-b7bd-02b72e2a5a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9902f105-b9ba-4511-b152-493f9b94ffb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_albert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " albert (TFAlbertMainLayer)  multiple                  17683968  \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  6150      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17690118 (67.48 MB)\n",
      "Trainable params: 17690118 (67.48 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5be1e11f-740d-4ac6-8b76-7a355c599b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 21:59:11.845496: W tensorflow/core/framework/op_kernel.cc:1816] OP_REQUIRES failed at cast_op.cc:122 : UNIMPLEMENTED: Cast string to float is not supported\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node Cast_1 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 736, in start\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n\n  File \"/tmp/ipykernel_18579/3652965245.py\", line 2, in <module>\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/transformers/modeling_tf_utils.py\", line 1679, in train_step\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 620, in update_state\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/metrics/base_metric.py\", line 708, in update_state\n\nCast string to float is not supported\n\t [[{{node Cast_1}}]] [Op:__inference_train_function_34174]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#fit model to train dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node Cast_1 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 736, in start\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n\n  File \"/tmp/ipykernel_18579/3652965245.py\", line 2, in <module>\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/transformers/modeling_tf_utils.py\", line 1679, in train_step\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 620, in update_state\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n\n  File \"/home/arjun/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/metrics/base_metric.py\", line 708, in update_state\n\nCast string to float is not supported\n\t [[{{node Cast_1}}]] [Op:__inference_train_function_34174]"
     ]
    }
   ],
   "source": [
    "#fit model to train dataset\n",
    "model.fit(train_dataset, epochs=3, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80396bf4-28cf-42d2-973a-ea5c4732694f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
